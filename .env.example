## KILLA CHAT (local dev)
## Backend keys (kept server-side). The frontend talks to the backend via /api (Vite proxy).

# ModelsLab (images)
MODELSLAB_API_KEY=

# Default Text2Img model for Create Images (allowed: nano-banana-pro, seedream-4.5)
MODELSLAB_IMAGEGEN_MODEL_ID=nano-banana-pro
# Video model for Create Video (ModelsLab Image-to-Video)
MODELSLAB_VIDEO_MODEL_ID=grok-imagine-video-i2v

# SerpAPI (DeepSearch)
SERPAPI_API_KEY=

# Clerk (auth)
# Frontend (Vite): exposed via envPrefix (NEXT_PUBLIC_)
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=YOUR_PUBLISHABLE_KEY

# Backend (Express)
CLERK_PUBLISHABLE_KEY=YOUR_PUBLISHABLE_KEY
CLERK_SECRET_KEY=YOUR_SECRET_KEY

# Knowledge Studio admin users (comma-separated Clerk user IDs)
# Example: user_abc123,user_def456
KNOWLEDGE_ADMIN_USER_IDS=

# Beta Early Access (license + credits)
# Comma-separated Clerk user IDs allowed to generate/list keys in admin endpoints.
BETA_ADMIN_USER_IDS=
# Public checkout URL shown to users in the license popup.
BETA_EARLY_ACCESS_CHECKOUT_URL=
# Manual delivery contact (mailto).
BETA_SUPPORT_EMAIL=

# LlamaIndex retrieval (optional for Knowledge Studio search)
LLAMAINDEX_ENABLED=false
# Optional explicit engine selector: "llamaindex" or leave empty.
KNOWLEDGE_SEARCH_ENGINE=
# Embedding provider: "ollama" (local/free) or "openai"
LLAMAINDEX_EMBED_PROVIDER=ollama
# Embedding model used by selected provider
LLAMAINDEX_EMBED_MODEL=nomic-embed-text
# Retriever top-k candidate pool before post-ranking
LLAMAINDEX_TOP_K=16
# Ollama local endpoint (used when LLAMAINDEX_EMBED_PROVIDER=ollama)
OLLAMA_BASE_URL=http://127.0.0.1:11434
# Required only when LLAMAINDEX_EMBED_PROVIDER=openai
OPENAI_API_KEY=

# Backend server port (optional)
PORT=8787
